
# Fetch mutation expression with pysam
# Author: Yuanhua Huang
# Date: 31-03-2018

import os
import sys
import gzip
import time
import math
import pysam
import subprocess
import multiprocessing
from optparse import OptionParser, OptionGroup

PROCESSED = 0
TOTAL_SAM = 1000
START_TIME = time.time()
VCF_HEADER = (
    '##fileformat=VCFv4.2\n'
    '##generated by mut_express.py v0.1.4\n'
    '##FILTER=<ID=PASS,Description="All filters passed">\n'
    '##FORMAT=<ID=DP,Number=1,Type=int,Description="total counts for ALT and '
    'REF">\n'
    '##FORMAT=<ID=AD,Number=1,Type=int,Description="total counts for ALT">\n'
    '##FORMAT=<ID=OTH,Number=1,Type=int,Description="total counts for other '
    'bases from REF and ALT">\n'
    '##FORMAT=<ID=ALL,Number=5,Type=int,Description="total counts for all '
    'bases in order of A,C,G,T,N">\n')

def show_progress(RV=None):
    global PROCESSED, TOTAL_SAM, START_TIME
    if RV is not None: 
        PROCESSED += 1
        bar_len = 20
        run_time = time.time() - START_TIME
        percents = 100.0 * PROCESSED / TOTAL_SAM
        filled_len = int(bar_len * percents / 100)
        bar = '=' * filled_len + '-' * (bar_len - filled_len)
        
        sys.stdout.write('\r[MutExpr] [%s] %.1f%% done in %.1f sec.' 
            % (bar, percents, run_time))
        sys.stdout.flush()
    return RV

def fetch_allele_count(vcf_lines, sam_file, mapq_min=5, 
                       mismatch_max=10**5, rlen_min=15, rm_duplicate=True):
    """Fetch allelic specific expression from a list of pysam objects
    """
    samFile = pysam.Samfile(sam_file)
    _chrom = vcf_lines[0][0]
    if _chrom in samFile.references:
        chrom_act = 0 # chrom = chrom
    elif _chrom.startswith("chr"):
        chrom_act = 1 # chrom = chrom.split("chr")[1]
    else:
        chrom_act = 2 # chrom = "chr" + chrom 
    # if _chrom not in samFile.references:
    #     print("Warning: can't find chrom %s in\n   -- %s" %(_chrom, sam_file))

    ADs, DPs = [], []
    OTHERs, outList = [], []
    for list_val in vcf_lines:
        # !!! be very careful with the POS: different start index
        POS = int(list_val[1]) - 1
        REF, ALT = list_val[3], list_val[4]
        alleles = {"A": 0, "C": 0, "G": 0, "T": 0, "N": 0}
        
        chrom = list_val[0]
        if chrom_act == 1: chrom = chrom.split("chr")[1]
        elif chrom_act == 2: chrom = "chr" + chrom

        r_prev = None
        reads = samFile.fetch(chrom, POS, POS+1)
        for _read in reads:
            # filters: map quality, read length, mismatch, duplicates
            if _read.mapq < mapq_min: continue
            if _read.rlen < rlen_min: continue
            if _read.rlen - len(_read.positions) > mismatch_max: continue
            if (rm_duplicate and r_prev is not None and 
                r_prev.qname == _read.qname and r_prev.seq == _read.seq):
                r_prev = _read; continue
            r_prev = _read
            try:
                idx = _read.positions.index(POS)
            except:
                continue
            alleles[_read.seq[idx].upper()] += 1
                
        ADs.append(alleles[ALT])
        DPs.append(alleles[ALT] + alleles[REF])
        OTHERs.append(sum(alleles.values()) - DPs[-1])
        if OTHERs[-1] + DPs[-1] > 0:
            all_str = ",".join([str(alleles[x]) for x in ["A", "C", "G", "T", "N"]])
            cnt_lst = [str(ADs[-1]), str(DPs[-1]), str(OTHERs[-1])]
            outList.append(":".join(cnt_lst + [all_str]))
        else:
            outList.append(":".join(["."] * 4))
    
    RV = {}
    RV["AD"] = ADs
    RV["DP"] = DPs
    RV["OTH"] = OTHERs
    RV["outList"] = outList
    return RV



def main():
    import warnings
    warnings.filterwarnings('error')

    # parse command line options
    parser = OptionParser()    
    parser.add_option("--inFile", "-i", dest="in_file", default=None,
        help=("Input file in vcf format, gzip compressed is supported."))
    parser.add_option("--outFile", "-o", dest="out_file", default=None,
        help=("Output file in vcf format."))
    parser.add_option("--samList", "-s", dest="sam_list", default=None,
        help=("A two-column tsv file: cell id and indexed sorted sam file."))
    
    group = OptionGroup(parser, "Optional arguments")
    group.add_option("--minRead", "-m", type="int", dest="min_read",
        default=1, help=("Minimum total reads for a SNP [default: %default]"))    
    group.add_option("--FILTER", "-F", dest="filter_in", default=None, 
        help=("Values in FILTER to keep, comma separated; otherwise all."))
    group.add_option("--nproc", "-p", type="int", dest="nproc", default=1,
        help="Number of subprocesses [default: %default]")
    group.add_option("--linePerRun", "-L", type="int", dest="line_per_run", 
        default=100000, help="Lines in a run, for memory [default: %default]")
    # group.add_option("--multiALT", action="store_true", dest="multi_ALT", 
    #     default=False, help=("Including sites with mutiple ALT."))
    
    parser.add_option_group(group)

    (options, args) = parser.parse_args()
    if len(sys.argv[1:]) == 0:
        print("Welcome to MutExpr!\n")
        print("use -h or --help for help on argument.")
        sys.exit(1)
    if options.in_file == None:
        print("Error: need --inFile for input vcf file.")
        sys.exit(1)
    if not os.path.isfile(options.in_file):
        print("Error: No such file\n    -- %s" %options.in_file)
        sys.exit(1)
    else:
        if options.in_file[-3:] == ".gz":
            infile = gzip.open(options.in_file, "rb")
        else:
            infile = open(options.in_file, "r")
    if options.sam_list == None:
        print("Error: need --samList for sam files.")
        sys.exit(1)
    else:
        with open(options.sam_list, "r") as f:
            sam_lines = [line.rstrip() for line in f]
        sam_ids = [x.split(",")[0] for x in sam_lines]
        sam_list = [x.split(",")[1] for x in sam_lines]
        
    # sam_ids = sam_ids[200:]
    # sam_list = sam_list[200:]
    
    nproc = options.nproc       
    min_read = options.min_read
    line_per_run = options.line_per_run
    if options.filter_in is None:
        filter_in = None
    else:
        filter_in = options.filter_in.split(",")
            
    try:
        outfile = open(options.out_file.split(".gz")[0], "w")
    except:
        print("Error: can't write outFile -- \n    %s" %options.out_file)
    global VCF_HEADER
    outfile.writelines(VCF_HEADER)
    
    # get vcf lines
    line_cnt = 0
    vcf_line_all = []
    for line in infile:
        line = line.decode('utf-8')
        if line.startswith("#"):
            if line.startswith("##contig="): 
                outfile.writelines(line)
            if line.startswith("#CHROM"):
                list_val = line.rstrip().split("\t")[:8] + ["FORMAT"] + [x for x in sam_ids]
                outfile.writelines("\t".join(list_val) + "\n")
        else:
            line_cnt += 1
            list_val = line.rstrip().split("\t")[:8]
            # Check FILTER
            if filter_in is not None:
                if filter_in.count(line.split("\t")[6]) < 1:
                    continue
            # Only supprot single neucleartide variantion
            if (max([len(x) for x in list_val[3].split(",")]) > 1 or 
                max([len(x) for x in list_val[4].split(",")]) > 1):
                continue
            # Only support one ALT; TODO: add more options
            if len(list_val[3].split(",")) + len(list_val[4].split(",")) > 2:
                print("Warning: mutliple REF: %s or ALT: %s" 
                      %(list_val[3], list_val[4]))
                continue
            vcf_line_all.append(list_val) #already splited
            
        ## for test only
        # if line_cnt > 50:
        #     break
    print("%d out %d lines for %d cells is being processed ... " 
          %(len(vcf_line_all), line_cnt, len(sam_ids)))
    
    
    # Note, we need multiple runs to limit the memory usage
    # which depends one number of cells and lines in each run.
    
    # fetch reads for each sam file
    n_run = math.ceil(len(vcf_line_all) / line_per_run)
    global TOTAL_SAM
    TOTAL_SAM = len(sam_ids) * n_run
    
    out_cnt = 0
    FORMAT = "AD:DP:OTH:ALL"
    for _run in range(n_run):
        if _run < n_run-1:
            vcf_lines = vcf_line_all[line_per_run*_run: line_per_run*(_run+1)]
        else:
            vcf_lines = vcf_line_all[line_per_run*_run:]
        
        # fetch reads in a run
        result = []
        if nproc > 1:
            pool = multiprocessing.Pool(processes=nproc)
            for _sam_file in sam_list:
                result.append(pool.apply_async(fetch_allele_count, (vcf_lines, 
                    _sam_file), callback=show_progress))
            pool.close()
            pool.join()
        else:
            for _sam_file in sam_list:
                result.append(fetch_allele_count(vcf_lines, _sam_file))
                show_progress(1)
        result = [res.get() if nproc > 1 else res for res in result]

        # output the results
        for i in range(len(vcf_lines)):
            AD_sum = sum([res["AD"][i] for res in result])
            DP_sum = sum([res["DP"][i] for res in result])
            OTH_sum = sum([res["OTH"][i] for res in result])
            if DP_sum + OTH_sum >= min_read:
                out_cnt += 1
                list_val = vcf_lines[i] + [FORMAT]
                list_val += [res["outList"][i] for res in result]
                outfile.writelines("\t".join(list_val) + "\n")
            
            ## for test
            # print(i, AD_sum, DP_sum, ADrev_sum, DPrev_sum)
            
    outfile.close()   
    
    print("")
    print("%d out of %d records added in %.1f sec" %(out_cnt, line_cnt, 
                                                    time.time() - START_TIME))
    
    bashCommand = "gzip -f %s" %(options.out_file.split(".gz")[0])
    pro = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)
    output = pro.communicate()[0]
        
if __name__ == "__main__":
    main()