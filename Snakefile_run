"""
Snakefile for one lane of single-cell fibroblast project (Raghd Rostom)

Author: Davis McCarthy
Affiliation: EMBL-EBI

Run from run directory
Run: snakemake -s ../../../Snakefile_run --jobs 2000 --latency-wait 30 --cluster-config ../../../cluster.json --cluster 'bsub -J {cluster.name} -q {cluster.queue} -n {cluster.n} -R "rusage[mem={cluster.memory}]" -M {cluster.memory}  -o {cluster.output} -e {cluster.error}'

Davis McCarthy, 20 November 2017
"""

import glob
import os
from subprocess import run
import subprocess
import pandas as pd
import re
import h5py

shell.prefix("set -euo pipefail;")

## reference files
references_dir = '/hps/nobackup/stegle/datasets/references/human/GRCh37/'
human_tx_fasta = 'Homo_sapiens.GRCh37.rel75.cdna.all.ERCC92.fa.gz'
human_gx_fasta = '/hps/nobackup/stegle/datasets/references/human/STAR_GRCh37.75_ERCC/GRCh37.p13.genome.ERCC92.fa'
human_fasta_unzipped =  'Homo_sapiens.GRCh37.rel75.cdna.all.ERCC92.fa'
kallisto_idx = 'Homo_sapiens.GRCh37.rel75.cdna.all.ERCC92.kallisto_v0.43_idx'
fasta = os.path.join(references_dir, 'human_tx_fasta')
fasta_unzipped = human_gx_fasta
fasta_dict = fasta_unzipped.replace('fa', 'dict')
fasta_idx = fasta_unzipped + '.fai'
#dbSnpVcf = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/dbsnp_138.hg19.vcf.gz'
dbSnpVcf = '/hps/nobackup/stegle/datasets/references/human/dbsnp_138.hg19.vcf.gz'
#dbSnpVcfSmall = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/dbsnp_138.hg19.excluding_sites_after_129_biallelic_snps.F.vcf.gz'
#dbSnpVcfSmall = '/hps/nobackup/stegle/datasets/references/human/dbsnp_138.hg19.excluding_sites_after_129_biallelic_snps.F.vcf.gz'
#dbSnpVcfSmall = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.vcf.gz'
dbSnpVcfSmall = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.Top1000ExpressedIpsGenes.Maf0.01.HWE0.0001.HipSci.vcf.gz'
reAlignmentIntervals = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/knownIndels.intervals'
knownIndelsMills = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/1000G_phase1.indels.hg19.sites.vcf.gz'
knownIndels100G = '/hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz'
## fasta files for GRCh38
fasta_GRCh38 = '/hps/nobackup/stegle/datasets/references/human/GRCh38/Homo_sapiens.GRCh38.rel85.cdna.all.ERCC92.fa.gz'
fasta_unzipped_GRCh38 = '/hps/nobackup/stegle/datasets/references/human/GRCh38/Homo_sapiens.GRCh38.dna.primary_assembly.ERCC92.fa'
fasta_dict_GRCh38 = '/hps/nobackup/stegle/datasets/references/human/GRCh38/Homo_sapiens.GRCh38.dna.primary_assembly.ERCC92.dict'
fasta_idx_GRCh38 = fasta_unzipped_GRCh38 + '.fai'
refflat_file = '/hps/nobackup/stegle/datasets/references/human/GRCh37/Homo_sapiens.GRCh37.75_ERCC.ref_flat.txt'
#HIPSCI_VCF = '/hps/nobackup/hipsci/scratch/genotypes/imputed/unreleased/hipsci.wec.gtarray.unreleased.REL-2016-09.imputed_phased.INFO_0.4_filtered.20160912.genotypes.allchr.temp_for_endodiff_20170217.vcf.gz'
#HIPSCI_VCF = '/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/INFO_0.4/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.INFO_0.4_filtered.20170327.genotypes.allchr.vcf.gz'
HIPSCI_VCF = '/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/Full/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.20170327.genotypes.allchr.vcf.gz'
HIPSCI_VCF_GNOMAD='/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/INFO_0.4/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.INFO_0.4_filtered.20170327.genotypes.allchr.gnomad.exomes.common.biallelic.contig_reordered.vcf.gz'

star_genome_files = ['chrLength.txt', 'chrNameLength.txt', 'chrName.txt', 'chrStart.txt', 'exonInfo.tab', 'Genome', 'genomeParameters.txt', 'SA', 'SAindex', 'sjdbInfo.txt', 'sjdbList.fromGTF.out.tab', 'sjdbList.out.tab', 'transcriptInfo.tab']

## define commands
python_cmd = '/nfs/software/stegle/users/davis/conda-envs/py3/bin/python'
python2_cmd = '/nfs/software/stegle/users/davis/conda-envs/py2/bin/python'
star_cmd = '/nfs/software/stegle/bin/STAR'
gatk_cmd = '/nfs/software/stegle/users/dseaton/java/jdk1.8.0_112/bin/java -Xmx50g -Xms8g -Djava.io.tmpdir=/hps/nobackup/hipsci/scratch/singlecell_endodiff/tmp -jar /hps/nobackup/stegle/users/mjbonder/tools/GATK/GenomeAnalysisTK.jar'
picard_cmd='/nfs/software/stegle/users/dseaton/java/jdk1.8.0_112/bin/java -jar /nfs/software/stegle/users/dseaton/picard/picard.jar'
salmon_cmd = '/nfs/software/stegle/users/davis/Salmon-0.8.2_linux_x86_64/bin/salmon'
salmon_idx = '/hps/nobackup/stegle/datasets/references/human/GRCh37/Homo_sapiens.GRCh37.rel75.cdna.all.ERCC92.salmon_v0.8.2_idx'
salmon_idx_GRCh38 = '/hps/nobackup/stegle/datasets/references/human/GRCh38/Homo_sapiens.GRCh38.rel85.cdna.all.ERCC92.salmon_v0.8.2_idx'
read_salmon_to_scesets_cmd = '../../../src/preprocessing/read_salmon_to_scesets.R'
rscript_cmd = 'singularity exec /hps/nobackup/hipsci/scratch/biocplus.img Rscript'
Rscript_cmd = '/nfs/software/stegle/users/davis/conda-envs/sc/bin/Rscript'
leafcutter_cmd = 'sh /hps/nobackup/stegle/users/mjbonder/tools/leafcutter/scripts/bam2junc.sh'
featurecounts_cmd = '/hps/nobackup/stegle/users/mjbonder/tools/subread-1.6.0-source/bin/featureCounts'

## parameter objects and samples
GENOME = 'genome.fa'
STAR_GENOME_DIR = '/hps/nobackup/stegle/datasets/references/human/STAR_GRCh37.75_ERCC'
star_genome_files = ['chrLength.txt', 'chrNameLength.txt', 'chrName.txt', 'chrStart.txt', 'exonInfo.tab', 'Genome', 'genomeParameters.txt', 'SA', 'SAindex', 'sjdbInfo.txt', 'sjdbList.fromGTF.out.tab', 'sjdbList.out.tab', 'transcriptInfo.tab']

## targets
star_genome_output = expand('{genome_dir}/{genome_files}', genome_dir=STAR_GENOME_DIR, genome_files=star_genome_files)

## read in crams from SS2 run
crams_all = glob.glob('cram/*.cram')

## define sample names
SAMPLES = [os.path.basename(w).replace('.cram', '') for w in crams_all]
gatk_split_bam_output = []
picard_QC_output = []
leaf_cutter_junc = []
feature_counts_output = []

fastqc_html_reports = expand('fastqc/{sample}.2pass.Aligned.sortedByCoord.out_fastqc.html', sample=SAMPLES)
cell_vcf_files = expand('vcf/{sample}/{sample}.filtered.vcf.gz', sample=SAMPLES)
# cell_vcf_files_clone_id = expand('vcf/{sample}/{sample}.clone_id.filtered.vcf.gz', sample=SAMPLES)
# cell_vcf_files_clone_id.append(expand('vcf/{sample}/{sample}.clone_id.filtered.vcf.gz.csi', sample=SAMPLES))
variant_donor_id_files = expand('donor_id/{sample}.donor_id.csv', sample=SAMPLES)
donor_id_all_files = 'donor_id_all.csv'
cells_merged_vcfs = 'cells_merged.vcf.gz'
merged_bams = expand('bam/merged/{sample}.bam', sample=SAMPLES)
salmon_results_GRCh37 = expand('quant_salmon/{sample}/quant.sf', sample=SAMPLES)
salmon_results_GRCh38 = expand('quant_salmon_GRCh38/{sample}/quant.sf', sample=SAMPLES)
# sces = expand('sces/sce.salmon.{genome}.preqc_tx.rds', genome=['GRCh37', 'GRCh38'])
# sces.append(expand('sces/sce.salmon.{genome}.preqc_gene.rds', genome=['GRCh37', 'GRCh38']))
sces = expand('sces/sce.salmon.{genome}.preqc_tx.rds', genome=['GRCh37'])
sces.append(expand('sces/sce.salmon.{genome}.preqc_gene.rds', genome=['GRCh37']))
scater_first_html_reports = expand('first_qc/salmon.{genome}.first_qc.html', genome=['GRCh37', 'GRCh38'])
seq_metadata_files = expand('meta/{sample}.meta', sample=SAMPLES)
seq_metadata_output = "seq_metadata.tsv"
gatk_split_bam_output.append(expand('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.bam', run=run, sample=SAMPLES))
picard_QC_output.append(expand('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.jump_metrics', run=run, sample=SAMPLES))
picard_QC_output.append(expand('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.rna_metrics', run=run, sample=SAMPLES))
leaf_cutter_junc.append(expand('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.primary.bam.junc', run=run, sample=SAMPLES))
feature_counts_output.append(expand('featureCounts/unique_counts/{sample}.gene.counts.unique.tsv', run=run, sample=SAMPLES))
feature_counts_output.append(expand('featureCounts/unique_counts/{sample}.exon.counts.unique.tsv', run=run, sample=SAMPLES))


hipsci_chr_vcf = []
hipsci_chr_vcf_idx = []
for i in range(1, 23):
    hipsci_chr_vcf.append('/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/Full/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.20170327.genotypes.chr%s.vcf.gz' %str(i))
    hipsci_chr_vcf_idx.append('/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/Full/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.20170327.genotypes.chr%s.vcf.gz.tbi' %str(i))

gatk_split_bam_output = [filename for elem in gatk_split_bam_output for filename in elem]
picard_QC_output = [filename for elem in picard_QC_output for filename in elem]
leaf_cutter_junc = [filename for elem in leaf_cutter_junc for filename in elem]
feature_counts_output = [filename for elem in feature_counts_output for filename in elem]


rule all:
    input:
        # HIPSCI_VCF,
        donor_id_all_files,
        "seq_metadata.tsv",
        sces,
        cells_merged_vcfs,
        picard_QC_output,
        #gatk_split_bam_output,
        feature_counts_output,
        leaf_cutter_junc


rule picard_CollectRnaSeqMetrics:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam'
    output:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.rna_metrics'
    shell:
        '{picard_cmd} CollectRnaSeqMetrics I={input} O={output} REF_FLAT={refflat_file} STRAND=NONE'


rule picard_CollectJumpingLibraryMetrics:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam'
    output:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.jump_metrics'
    shell:
        '{picard_cmd} CollectJumpingLibraryMetrics I={input} O={output}'


rule build_star_genome_indexes:
    input:
        fasta=fasta_unzipped,
        annotation='/hps/nobackup/stegle/datasets/references/human/GRCh37/gencode.v19.annotation_ERCC.gtf'
    output:
        star_genome_output
    threads: 8
    shell:
        '{star_cmd} --runMode genomeGenerate --genomeDir {STAR_GENOME_DIR} '
        '--genomeFastaFiles {input.fasta} --runThreadN {threads} '
        '--sjdbGTFfile {input.annotation} --sjdbOverhang 100'


rule create_fasta_index:
    input:
        fasta_unzipped
    output:
        fasta_idx
    shell:
        'samtools faidx {input}'


rule create_fasta_dict:
    input:
        fasta_unzipped
    output:
        fasta_dict
    shell:
        '{picard_cmd} CreateSequenceDictionary R={input} O={output}'


rule create_vcf_file_list:
    output:
        'data_raw/Full-2017-03-29_genotype_vcf_file_list.txt'
    run:
        with open(output[0], "w+") as outfile:
                for i in range(1, 23):
                        outfile.write('/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/Full/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.20170327.genotypes.chr%s.vcf.gz\n' %str(i))
                        #outfile.write('/hps/nobackup/hipsci/scratch/genotypes/imputed/2017-03-27/INFO_0.4/hipsci.wec.gtarray.HumanCoreExome.imputed_phased.INFO_0.4_filtered.20170327.genotypes.chr%s.vcf.gz\n' %str(i))


rule generate_new_tabix_idx:
    input:
        hipsci_chr_vcf
    output:
        hipsci_chr_vcf_idx
    run:
        for chrom in hipsci_chr_vcf:
            print(chrom)
            cmd = 'tabix -f -p vcf ' + chrom
            print(cmd)
            subprocess.run(cmd, shell = True)


rule create_hipsci_vcf:
    input:
        'data_raw/Full-2017-03-29_genotype_vcf_file_list.txt'
    output:
        vcf=HIPSCI_VCF,
        vcf_idx=HIPSCI_VCF + '.tbi'
    shell:
        """
        bcftools concat -f {input} -O z > {output.vcf}
        tabix -f -p vcf {output.vcf}
        """


rule build_salmon_index:
    input:
        fasta
    output:
        salmon_idx
    shell:
        '{salmon_cmd} index -t {input} -i {output} --type quasi -k 31 '
        '--perfectHash'

    
rule build_salmon_index_GRCh38:
    input:
        fasta_GRCh38
    output:
        salmon_idx_GRCh38
    shell:
        '{salmon_cmd} index -t {input} -i {output} --type quasi -k 31 '
        '--perfectHash'


rule seq_metadata_collect:
    input:
        files=seq_metadata_files
    output:
        'seq_metadata.tsv'
    params:
        dir='meta/',
    run:
        import os
        import glob
        import re
        import pandas as pd
        metafiles = glob.glob(os.path.join(params.dir, '*.meta'))
        seq_sample_names = [os.path.basename(x).replace(".meta", "") for x in metafiles]
        metadict = {}
        for fname in metafiles:
            tmpdict = {}
            with open(fname) as f:
                current_attribute = ''
                for line in f:
                    if re.search('^attribute', line):
                        current_attribute = line.replace('attribute: ', '').strip()
                    if re.search('^value', line):
                        tmpdict[current_attribute] = line.replace('value: ', '').strip()
                metadict[os.path.basename(fname).replace(".meta", "")] = tmpdict
        df = pd.DataFrame(metadict).transpose()
        df['cram_id'] = df.index
        df.to_csv(output[0], index=False, sep='\t')


rule cram2fastq:
    input:
        'cram/{sample}.cram'
    output:
        fq1=temp('fastq/{sample}_1.fastq'),
        fq2=temp('fastq/{sample}_2.fastq')
    shell:
        """
        samtools view -u {input} | \
        samtools collate -uOn 128 - tmp/tmp-prefix-{wildcards.sample} | \
        samtools fastq -F 0xB00 -1 {output.fq1} -2 {output.fq2} -
        """
        #'samtools sort -m 10G -n -T %s {input} | samtools fastq -F 0xB00 -1 {output.fq1} -2 {output.fq2} -'
        #'samtools fastq -t -1 {output.fq1} -2 {output.fq2} {input}'


rule trim_fastq_SS2:
    input:
        fq1="fastq/{sample}_1.fastq",
        fq2="fastq/{sample}_2.fastq"
    output:
        fq1='fastq/{sample}_1_val_1.fq.gz',
        fq2='fastq/{sample}_2_val_2.fq.gz'
    priority: 6
    shell:
        '/nfs/software/stegle/trim_galore/trim_galore --gzip '
        '--output_dir fastq '
        '--length 40 --paired '
        '{input.fq1} {input.fq2}'


rule salmon_quant:
    input:
        sidx=salmon_idx,
        fq1='fastq/{sample}_1_val_1.fq.gz',
        fq2='fastq/{sample}_2_val_2.fq.gz'
    output:
        'quant_salmon/{sample}/quant.sf'
    threads: 4
    params:
        folder='quant_salmon/{sample}/'
    shell:
        '{salmon_cmd} quant -i {input.sidx} -l IU '
        '-1 {input.fq1} -2 {input.fq2} '
        '--seqBias --gcBias --threads {threads} --useVBOpt ' 
        '-o {params.folder}'


rule salmon_quant_GRCh38:
    input:
        sidx=salmon_idx_GRCh38,
        fq1='fastq/{sample}_1_val_1.fq.gz',
        fq2='fastq/{sample}_2_val_2.fq.gz'
    output:
        'quant_salmon_GRCh38/{sample}/quant.sf'
    threads: 4
    params:
        folder='quant_salmon_GRCh38/{sample}/'
    shell:
        '{salmon_cmd} quant -i {input.sidx} -l IU '
        '-1 {input.fq1} -2 {input.fq2} '
        '--seqBias --gcBias --threads {threads} --useVBOpt ' 
        '-o {params.folder}'


rule align_with_star_2pass_SS2:
    input:
        star_genome_output,
        genome_dir=STAR_GENOME_DIR,
        fq1='fastq/{sample}_1_val_1.fq.gz',
        fq2='fastq/{sample}_2_val_2.fq.gz'
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.out.bam')
    params:
        prefix='star/{sample}/{sample}.2pass.'
    threads: 12
    shell:
        '{star_cmd} --genomeDir {input.genome_dir} '
        '--readFilesIn {input.fq1} {input.fq2} '
        '--outFileNamePrefix {params.prefix} '
        '--outSAMtype BAM Unsorted '
        '--alignSJoverhangMin 8 '
        '--alignSJDBoverhangMin 1 --genomeLoad NoSharedMemory '
        '--alignIntronMin 20 --alignIntronMax 1000000 '
        '--alignMatesGapMax 1000000 --sjdbScore 2 '
        '--outFilterType BySJout '
        '--outFilterMultimapNmax 20 --outFilterMismatchNmax 999 '
        '--outFilterMismatchNoverLmax 0.04 '
        '--outFilterScoreMinOverLread 0.33 --outFilterMatchNminOverLread 0.33 '
        '--outSAMstrandField intronMotif '
        '--outFilterIntronMotifs RemoveNoncanonical '
        '--outSAMattributes NH HI NM MD AS XS --outSAMunmapped Within '
        '--runThreadN {threads} --twopassMode Basic '
        '--readFilesCommand zcat '


rule sort_alignment:
    input:
        'star/{sample}/{sample}.2pass.Aligned.out.bam'
    output:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam'
    threads: 4
    shell:
        'samtools sort -m 12G -@ 4 -O bam -o {output} {input}'


rule index_star_bams:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam'
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam.bai')
    shell:
        'samtools index {input} '


rule picard_read_groups:
    input:
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam'
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.rgadded.bam')
    shell:
        '{picard_cmd} AddOrReplaceReadGroups I={input.bam} O={output} SO=coordinate '
        'RGID={wildcards.sample} RGLB={wildcards.sample} '
        'RGPL=ILLUMINA RGPU=MACHINE1 RGSM={wildcards.sample}'


rule picard_mark_dups:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.rgadded.bam'
    output:
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam',
        metrics='star/{sample}/{sample}.output.metrics'
    shell:
        '{picard_cmd} MarkDuplicates I={input} O={output.bam} CREATE_INDEX=true '
        'VALIDATION_STRINGENCY=SILENT M={output.metrics} REMOVE_DUPLICATES=true'


rule write_primary_alignment_bam:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam'
    output:
        bam_primary='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.primary.bam'
    params:
        headerTmp = 'star/{sample}/header.sam'
    shell:
        'samtools view -H {input} > {params.headerTmp}; '
        'samtools view {input} | grep "NH:i:1" | cat {params.headerTmp} - | samtools view -Sb - > {output.bam_primary}; '
        'rm {params.headerTmp}'


rule create_junc_files:
    input:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.primary.bam'
    output:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.primary.bam.junc'
    shell:
        '{leafcutter_cmd} {input} {output} '


rule count_genes_unique:
    input:
        bam = 'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam',
        annotation='/hps/nobackup/hipsci/scratch/trans_eqtls/Annotation/Homo_sapiens.GRCh37.75_c_hg19_rmsk_TE_ensemblChrmapping.filtered.hipsciexpressed.gtf'
    output:
        'featureCounts/unique_counts/{sample}.gene.counts.unique.tsv'
    priority: 4
    shell:
        '{featurecounts_cmd} '
        ' -B -C -p --primary -R CORE'
        ' -a {input.annotation} -g gene_id '
        ' -o  {output} {input.bam}'


rule count_features_unique:
    input:
        bam = 'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam',
        annotation='/hps/nobackup/hipsci/scratch/trans_eqtls/Annotation/Homo_sapiens.GRCh37.75_c_hg19_rmsk_TE_ensemblChrmapping.filtered.hipsciexpressed.gtf'
    output:
        'featureCounts/unique_counts/{sample}.exon.counts.unique.tsv'
    priority: 4
    shell:
        '{featurecounts_cmd} '
        ' -F GTF -B -C -p --primary -O '
        ' -a {input.annotation} -g exon_id '
        ' -o  {output} {input.bam}'


rule split_n_trim_gatk:
    input:
        fasta=fasta_unzipped,
        fai=fasta_idx,
        fa_dict=fasta_dict,
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.dedup.bam'
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.bam')
    shell:
        '{gatk_cmd} -T SplitNCigarReads -R {input.fasta} -I {input.bam} -o {output} '
        '-rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 '
        '-U ALLOW_N_CIGAR_READS '


rule indel_realignment_gatk:
    input:
        fasta=fasta_unzipped,
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.bam',
        targetIntervals=reAlignmentIntervals,
        known1=knownIndelsMills,
        known2=knownIndels100G
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bam')
    shell:
        '{gatk_cmd} -T IndelRealigner -R {input.fasta} -I {input.bam} '
        '-targetIntervals {input.targetIntervals} -known {input.known1} -known {input.known2} '
        '-U ALLOW_N_CIGAR_READS --consensusDeterminationModel KNOWNS_ONLY --LODThresholdForCleaning 0.4  '
        '-o {output}'


rule base_recalibrator_gatk:
    input:
        fasta=fasta_unzipped,
        dbSnp=dbSnpVcf,
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bam',
        known1=knownIndelsMills,
        known2=knownIndels100G
    output:
        temp('star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr')
    shell:
        '{gatk_cmd} -T BaseRecalibrator -R {input.fasta} -I {input.bam} '
        '-knownSites {input.known1} -knownSites {input.known2} -knownSites {input.dbSnp} '
        '-nct 2 '
        '-o {output}'


rule recalibrated_writer_gatk:
    input:
        fasta=fasta_unzipped,
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bam',
        bqsr='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr'
    output:
        'star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr.bam'
    shell:
        '{gatk_cmd} -T PrintReads -R {input.fasta} -I {input.bam} '
        '-BQSR {input.bqsr} -nct 2 '
        '-o {output}'


# rule call_variants_gatk:
#     input:
#         fasta=fasta_unzipped,
#         fai=fasta_idx,
#         fa_dict=fasta_dict,
#         dbSnp=dbSnpVcf,
#         dbSnpSmall= dbSnpVcfSmall,
#         bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr.bam'
#     output:
#         temp('vcf/{sample}/{sample}.unfiltered.vcf')
#     shell:
#         '{gatk_cmd} -T HaplotypeCaller -R {input.fasta} -I {input.bam} '
#         '-dontUseSoftClippedBases '
#         '-D {input.dbSnp} -gt_mode GENOTYPE_GIVEN_ALLELES '
#         '-alleles {input.dbSnpSmall} -L {input.dbSnpSmall} -o {output}' 


## generate bcftools targets file
# bcftools query -f'%CHROM\t%POS\t%REF,%ALT\n' /hps/nobackup/stegle/users/mjbonder/ref/GenotypingInformation/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.Top1000ExpressedIpsGenes.Maf0.01.HWE0.0001.HipSci.vcf.gz | bgzip -c > /hps/nobackup/hipsci/scratch/singlecell_endodiff/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.Top1000ExpressedIpsGenes.Maf0.01.HWE0.0001.HipSci.als.tsv.gz && tabix -s1 -b2 -e2 /hps/nobackup/hipsci/scratch/singlecell_endodiff/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.Top1000ExpressedIpsGenes.Maf0.01.HWE0.0001.HipSci.als.tsv.gz

rule call_variants_mpileup_fthicov:
    input:
        fasta=fasta_unzipped,
        fai=fasta_idx,
        fa_dict=fasta_dict,
        dbSnp=dbSnpVcf,
        dbSnpSmall= dbSnpVcfSmall,
        targets='/hps/nobackup/hipsci/scratch/singlecell_endodiff/dbsnp_138.hg19.biallelicSNPs.HumanCoreExome12.Top1000ExpressedIpsGenes.Maf0.01.HWE0.0001.HipSci.als.tsv.gz',
        bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr.bam'
    output:
        mpi=temp('vcf/{sample}/{sample}.filtered.bcf.gz'),
        midx=temp('vcf/{sample}/{sample}.filtered.bcf.gz.csi'),
        vcf='vcf/{sample}/{sample}.filtered.vcf.gz',
        idx='vcf/{sample}/{sample}.filtered.vcf.gz.csi'
    shell:
        """
        mkdir tmp/tmp-{wildcards.sample}
        bcftools mpileup -E -Ob --skip-indels -R {input.dbSnpSmall} \
        -f {input.fasta} --annotate AD,DP,SP,INFO/AD {input.bam} -o {output.mpi}
        bcftools index {output.mpi}
        bcftools call -R {input.dbSnpSmall} -T {input.targets} -m -Ou {output.mpi} | \
        bcftools filter -Ou -i'DP>3 && QUAL>20' | \
        bcftools sort -T tmp/tmp-{wildcards.sample} --max-mem 2G -Oz -o {output.vcf}
        bcftools index {output.vcf}
        """
        # bcftools index {output.vcf}
        # bcftools filter -Ou -i 'TYPE="snp"' -e 'DP<=3' | \
        # -i'TYPE="snp" && DP>3 && QUAL>20'
# -T {input.targets} 

# rule call_variants_yuanhua:
#     input:
#         dbSnpSmall= dbSnpVcfSmall,
#         hipsci_vcf=HIPSCI_VCF,
#         bam='star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr.bam'
#     output:
#         vcf='vcf/{sample}/{sample}.filtered.vcf.gz',
#         idx='vcf/{sample}/{sample}.filtered.vcf.gz.csi',
#         tmp=temp('tmp_{sample}_bam_list.csv')
#     threads: 1
#     shell:
#         """
#         echo "{wildcards.sample},{input.bam}" > {output.tmp}
#         /nfs/software/stegle/users/davis/conda-envs/sc/bin/python \
#         ../../../src/Python/mut_express.py -i {input.hipsci_vcf} \
#         -o {output.vcf} -s {output.tmp} -m 5 -p {threads}
#         """



# rule filter_variants_gatk:
#     input:
#         vcf='vcf/{sample}/{sample}.unfiltered.vcf',
#         fasta=fasta_unzipped,
#         fai=fasta_idx,
#         fa_dict=fasta_dict
#     output:
#         temp('vcf/{sample}/{sample}.filtered.vcf')
#     shell:
#         '{gatk_cmd} -T VariantFiltration -R {input.fasta} -V {input.vcf} '
#         '-window 35 -filterName FS -filter "FS > 30.0" '
#         '-filterName QD -filter "QD < 2.0" -o {output}'
#         # '{gatk_cmd} -T VariantFiltration -R {input.fasta} -V {input.vcf} '
#         # '-window 35 -cluster 3 -filterName FS -filter "FS > 30.0" '
#         # '-filterName QD -filter "QD < 2.0" -o {output}'
        

# rule bgzip_vcf:
#     input:
#         'vcf/{sample}/{name}.filtered.vcf'
#     output:
#         f1='vcf/{sample}/{name}.filtered.vcf.gz',
#         f2='vcf/{sample}/{name}.filtered.vcf.gz.csi'
#     shell:
#         """
#         vcf-sort {input} | bgzip -c > {output.f1}
#         bcftools index {output.f1}
#         """


rule singlecell_variant_list:
    input:
        'vcf/{sample}/{sample}.filtered.vcf.gz'
    output:
        temp('vcf/{sample}/{sample}.variant_list.txt')
    shell:
        """
        set +euo pipefail
        echo -e "1\\t1\\tA\\tC" > {output}
        bcftools view -O v {input} | grep -v ^# | awk \'{{sub(/chr/,""); print $1"\\t"$2"\\t"$4"\\t"$5}}\' >> {output}
        set -euo pipefail
        """


rule filter_hipsci_overlap_variants:
    input:
        sc_vcf='vcf/{sample}/{sample}.filtered.vcf.gz',
        sc_vcf_idx='vcf/{sample}/{sample}.filtered.vcf.gz.csi',
        variant_list='vcf/{sample}/{sample}.variant_list.txt',
        hipsci_vcf=HIPSCI_VCF
    output:
        tmp=temp('vcf/{sample}/{sample}.tmp.vcf.gz'),
        vcf=temp('vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz'),
        csi=temp('vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz.csi')
    shell:
        """
        bcftools view -o {output.tmp} -O z -l 9 -R {input.variant_list} {input.hipsci_vcf}
        vcf-sort {output.tmp} | bgzip -c > {output.vcf}
        bcftools index {output.vcf}
        """


# rule identify_donor_runs:
#     input:
#         sc_vcf='vcf/{sample}/{sample}.filtered.vcf.gz',
#         hipsci_vcf='vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz',
#         hipsci_vcf_idx='vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz.csi'
#     output:
#         'donor_id/{sample}.donor_id.csv'
#     params:
#         prefix='donor_id/{sample}.donor_id'
#     shell:
#         '{rscript_cmd} ../../../../singlecell_endodiff/src/R/identify_donor_small_vcf.R '
#         '--input_file "{input.sc_vcf}" '
#         '--donor_lines "vass;wuye;wetu" '
#         '--donor_vcf {input.hipsci_vcf} '
#         '--output_prefix "{params.prefix}" '


rule identify_donor_runs:
    input:
        sc_vcf='vcf/{sample}/{sample}.filtered.vcf.gz',
        hipsci_vcf='vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz',
        hipsci_vcf_idx='vcf/{sample}/{sample}.filtered.hipsci.overlap.vcf.gz.csi'
    output:
        'donor_id/{sample}.donor_id.csv'
    params:
        prefix='donor_id/{sample}.donor_id'
    shell:
        '{Rscript_cmd} ../../../src/R/identify_donor_small_vcf_cardelino.R '
        '--input_file "{input.sc_vcf}" '
        '--donor_lines "vass;wuye;wetu" '
        '--donor_vcf {input.hipsci_vcf} '
        '--output_prefix "{params.prefix}" '


rule identify_donor_collect:
    input:
        files=variant_donor_id_files
    output:
        'donor_id_all.csv'
    params:
        dir='donor_id/'
    run:
        import pandas as pd
        import glob
        import os
        input_files = glob.glob(os.path.join(params.dir, '*.donor_id.csv'))
        df_list = {}
        for infile in input_files:
            df_tmp = pd.read_csv(infile)
            df_list[infile] = df_tmp
        df_out = pd.concat(df_list)
        df_out.to_csv(output[0], index=False)


rule merge_cell_vcfs:
    input:
        files=cell_vcf_files
    output:
        'cells_merged.vcf.gz'
    params:
        dir='vcf'
    shell:
        """
        set +euo pipefail
        bcftools merge -O z -o {output} $(ls -1 {params.dir}/*/*.filtered.vcf.gz | perl -pe 's/\n/ /g')
        set -euo pipefail
        """


rule salmon_to_sceset_GRCh37:
    input:
        files=salmon_results_GRCh37
    output:
        'sces/sce.salmon.GRCh37.preqc_tx.rds',
        'sces/sce.salmon.GRCh37.preqc_gene.rds'
    params:
        input_dir='quant_salmon',
        output_prefix='sces/sce.salmon.GRCh37.preqc'
    shell:
        '{rscript_cmd} {read_salmon_to_scesets_cmd} '
        '--input_dir {params.input_dir} '
        '--output_prefix {params.output_prefix} '
        '--biomart feb2014.archive.ensembl.org'


rule salmon_to_sceset_GRCh38:
    input:
        files=salmon_results_GRCh38
    output:
        'sces/sce.salmon.GRCh38.preqc_tx.rds',
        'sces/sce.salmon.GRCh38.preqc_gene.rds',
        'sces/sce.salmon.GRCh38.preqc.feather'
    params:
        input_dir='quant_salmon_GRCh38',
        output_prefix='sces/sce.salmon.GRCh38.preqc'
    shell:
        '{rscript_cmd} {read_salmon_to_scesets_cmd} '
        '--input_dir {params.input_dir} '
        '--output_prefix {params.output_prefix} '
        '--biomart jul2016.archive.ensembl.org'


rule rough_qc:
    input:
        'sces/sce.salmon.{genome}.preqc_gene.rds'
    output:
        'first_qc/salmon.{genome}.first_qc.html'
    shell:
        '{rscript_cmd} ../../../../singlecell_endodiff/src/R/compile_report.R '
        '-i {input} -o {output} '
        '--template ../../../src/Rmd/rough_qc_template.Rmd '


# rule fastqc_reports:
#     input:
#         'Data/{run}/star/{sample}/{sample}.2pass.Aligned.sortedByCoord.split.realigned.bqsr.bam'
#     output:
#         'Data/{run}/star/{sample}/{sample}.2pass.Aligned.sortedByCoord.out.bam_fastqc.html'
#     params:
#         output_dir="Data/{run}/fastqc/"
#     shell:
#         '/nfs/software/stegle/FastQC/fastqc -o {params.output_dir} {input}'

## Merging bams to create super-bam for variant calling
#  ls 21*/star/*/*sortedByCoord.split.realigned.bqsr.bam > bam_list.txt
# bamtools merge -list bam_list.txt -out ss2_merged.bam

## Call variants for all cells individually, but in one file
# /nfs/software/stegle/users/dseaton/java/jdk1.8.0_112/bin/java -Xmx50g -Xms8g -Djava.io.tmpdir=/hps/nobackup/hipsci/scratch/singlecell_endodiff/tmp -jar /hps/nobackup/stegle/users/mjbonder/tools/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller -R /hps/nobackup/stegle/datasets/references/human/STAR_GRCh37.75_ERCC/GRCh37.p13.genome.ERCC92.fa -I ss2_new_merged.bam -dontUseSoftClippedBases -stand_call_conf 20.0 -o ss2_new_merged_bam_output.vcf
## change readgroups to pool reads across cells
# /nfs/software/stegle/users/dseaton/java/jdk1.8.0_112/bin/java -jar /nfs/software/stegle/users/dseaton/picard/picard.jar AddOrReplaceReadGroups I=ss2_merged.bam O=ss2_merged_repRG.bam SO=coordinate RGID=22379 RGLB=22379 RGSM=22379 RGPL=illumina RGPU=sanger
## call variants for pooled reads
# /nfs/software/stegle/users/dseaton/java/jdk1.8.0_112/bin/java -Xmx50g -Xms8g -Djava.io.tmpdir=/hps/nobackup/hipsci/scratch/singlecell_endodiff/tmp -jar /hps/nobackup/stegle/users/mjbonder/tools/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller -R /hps/nobackup/stegle/datasets/references/human/STAR_GRCh37.75_ERCC/GRCh37.p13.genome.ERCC92.fa -I ss2_new_merged_repRG.bam -dontUseSoftClippedBases -stand_call_conf 20.0 -o ss2_new_merged_bam_pooled.vcf

